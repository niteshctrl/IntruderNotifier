{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "1. [Telegram Send Alert](#Telegram-Send-Alert)\n",
    "2. [Postprocessing](#Prediction-and-PostProcessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telegram Send Alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_alert(filename, alert_type, method='photo'):   # 'photo', 'document', animation\n",
    "    with open('bot_cred.json','r') as json_file:\n",
    "        bot_creds = json.load(json_file)\n",
    "        \n",
    "    files = {method:open(filename, 'rb')}\n",
    "    \n",
    "    resp = requests.post('https://api.telegram.org/bot' + bot_creds['bot_token'] + \\\n",
    "        '/send'+ method + '?chat_id=' + bot_creds['bot_chatID'] + '&caption=' + alert_type, files=files)\n",
    "\n",
    "    return resp.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "send_alert('cheers.gif', 'Testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction and PostProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model('files/YoloV3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image preprocess function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image, target_size=(416,416)):\n",
    "    '''\n",
    "    Processes the given image to feed the model(Rescaling by factor 1./255 and\n",
    "    resizing to target_shape)\n",
    "\n",
    "    Arguments:\n",
    "    filename -- Filepath of the image to be processed\n",
    "    target_shape -- Shape of the image accepted by the model(Width, Height)\n",
    "\n",
    "    Returns:\n",
    "    image -- Array of the resized input image to target_size\n",
    "    width -- Original width of the image\n",
    "    height -- Original height of the image\n",
    "    '''\n",
    "    \n",
    "    original_height, original_width,_ = image.shape\n",
    "\n",
    "    image = tf.image.resize(image, target_size, method='nearest')    # Resizes the image    \n",
    "    image /= 255  # Normalization\n",
    "    image = np.expand_dims(image, 0)    # To make the image a batch of images with a single image. Output shape=(batch_size, height, width, channels)\n",
    "\n",
    "    return image, original_width, original_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'image1.jpg'\n",
    "#img = cv2.imread(filename)\n",
    "image_array, original_width, original_height = preprocess_image(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''decode_netout() will take each one of the NumPy arrays, one at a time, and\n",
    "decode the candidate bounding boxes and class predictions. Further, any bounding\n",
    "boxes that donâ€™t confidently describe an object (e.g. all class probabilities\n",
    "are below a threshold) are ignored. We will use a probability of 60% or 0.6. The\n",
    "function returns a list of BoundBox instances that define the corners of each \n",
    "bounding box in the context of the input image shape and class probabilities.'''\n",
    "\n",
    "'''def _sigmoid(x):\n",
    "\treturn 1. / (1. + np.exp(-x))\n",
    " '''\n",
    "\n",
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "        self.objness = objness\n",
    "        self.classes = classes\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    "\n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    "        return self.label\n",
    "\n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    "        return self.score\n",
    "        \n",
    "\n",
    "def decode_netout(netout, anchors, obj_threshold, net_w=416, net_h=416):\n",
    "    grid_h, grid_w = netout.shape[:2] # Number of Grid divisions\n",
    "    nb_box = 3 # Number of anchor boxes\n",
    "    netout = netout.reshape((grid_h, grid_w, nb_box, -1)) # Convert (13,13,225) to (13,13,3,85)\n",
    "    nb_classes = netout.shape[-1] - 5 # 5 dedected due to pc, bx, by, bh, bw\n",
    "    boxes = []\n",
    "\n",
    "    netout[..., :2] = tf.math.sigmoid(netout[..., :2])\n",
    "    netout[..., 4:] = tf.math.sigmoid(netout[..., 4:])\n",
    "    netout[..., 5:] = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "    netout[..., 5:] *= netout[..., 5:] > obj_threshold\n",
    "\n",
    "    for i in range(grid_h*grid_w):\n",
    "        row = i / grid_w\n",
    "        col = i % grid_w\n",
    "\n",
    "        for b in range(nb_box):\n",
    "            objectness = netout[int(row)][int(col)][b][4]\n",
    "            if objectness.all() <= obj_threshold:\n",
    "                continue\n",
    "            x, y, w, h = netout[int(row)][int(col)][b][:4]\n",
    "            x = (col + x) / grid_w\n",
    "            y = (row + y) / grid_h\n",
    "            w = anchors[2 * b + 0] * np.exp(w) / net_w\n",
    "            h = anchors[2 * b + 1] * np.exp(h) / net_h\n",
    "\n",
    "            classes = netout[int(row)][col][b][5:]\n",
    "            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
    "            boxes.append(box)\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the anchor boxes\n",
    "anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
    "model_input_shape = (416, 416)\n",
    "\n",
    "# Define the probability threshold for detected objects\n",
    "class_threshold = 0.6\n",
    "\n",
    "\n",
    "'''We need a list of strings containing the class labels known to the model\n",
    " in the correct order used during training, specifically those class labels\n",
    "  from the MSCOCO dataset. Thankfully, this is provided in the experiencor\n",
    "  script.'''\n",
    "\n",
    "# define the labels\n",
    "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\n",
    "    \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
    "    \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n",
    "    \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n",
    "    \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
    "    \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\n",
    "    \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "    \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\",\n",
    "    \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\n",
    "    \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.20888684174189198 0.29292368478852615 10647\n"
     ]
    }
   ],
   "source": [
    "boxes = list()\n",
    "for i in range(len(yhat)):\n",
    "    boxes += decode_netout(yhat[i][0],\n",
    "                            anchors[i],\n",
    "                            class_threshold,\n",
    "                            model_input_shape[0],\n",
    "                            model_input_shape[1]\n",
    "                            )\n",
    "print(boxes[0].xmin, boxes[10].ymax, len(boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(10647):\n",
    "    if boxes[i].objness > 0.5:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To rescale the bboxes to fit on the objects of the original image\n",
    "\n",
    "def rescale_yolo_boxes(boxes, image_w, image_h, net_h, net_w):\n",
    "    new_w, new_h = net_w, net_h\n",
    "    for i in range(len(boxes)):\n",
    "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
    "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-133 140\n"
     ]
    }
   ],
   "source": [
    "rescale_yolo_boxes(boxes, original_width, original_height, model_input_shape[0], model_input_shape[1])\n",
    "\n",
    "print(boxes[0].xmin, boxes[10].ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _interval_overlap(interval_a, interval_b):\n",
    "\tx1, x2 = interval_a\n",
    "\tx3, x4 = interval_b\n",
    "\tif x3 < x1:\n",
    "\t\tif x4 < x1:\n",
    "\t\t\treturn 0\n",
    "\t\telse:\n",
    "\t\t\treturn min(x2,x4) - x1\n",
    "\telse:\n",
    "\t\tif x2 < x3:\n",
    "\t\t\t return 0\n",
    "\t\telse:\n",
    "\t\t\treturn min(x2,x4) - x3\n",
    " \n",
    "def bbox_iou(box1, box2):\n",
    "\tintersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "\tintersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "\tintersect = intersect_w * intersect_h\n",
    "\tw1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "\tw2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "\tunion = w1*h1 + w2*h2 - intersect\n",
    "\treturn float(intersect) / union\n",
    "\n",
    "def do_nms(boxes, nms_threshold):\n",
    "    if len(boxes) > 0:\n",
    "        nb_classes = len(boxes[0].classes)\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    for c in range(nb_classes):\n",
    "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "        for i in range(len(sorted_indices)):\n",
    "            index_i = sorted_indices[i]\n",
    "            if boxes[index_i].classes[c] == 0:\n",
    "                continue\n",
    "            for j in range(i+1, len(sorted_indices)):\n",
    "                index_j = sorted_indices[j]\n",
    "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_threshold:\n",
    "                    boxes[index_j].classes[c] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10647 -133 140\n"
     ]
    }
   ],
   "source": [
    "do_nms(boxes, 0.5)\n",
    "print(len(boxes),boxes[0].xmin, boxes[10].ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(10647):\n",
    "    if boxes[i].objness > 0.5:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_boxes(boxes, labels, threshold=0.6):\n",
    "    v_boxes, v_labels, v_scores = list(), list(), list()\n",
    "    \n",
    "    for box in boxes:\n",
    "        for i in range(len(labels)):\n",
    "            if box.classes[i] > threshold:\n",
    "                v_boxes.append(box)\n",
    "                v_labels.append(labels[i])\n",
    "                v_scores.append(box.classes[i]*100)\n",
    "    return v_boxes, v_labels, v_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person 98.77431988716125\n"
     ]
    }
   ],
   "source": [
    "v_boxes, v_labels, v_scores = filter_boxes(boxes, labels, class_threshold)\n",
    "\n",
    "\n",
    "# summarize what we found\n",
    "for i in range(len(v_boxes)):\n",
    "\tprint(v_labels[i], v_scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "for i in range(len(v_boxes)):\n",
    "    box = v_boxes[i]\n",
    "    y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Image', frame)    # Read Image\n",
    "\n",
    "k = cv2.waitKey(0)\n",
    "if k == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    img_array, original_width, original_height = preprocess_image(frame)\n",
    "    yhat = model.predict(img_array)\n",
    "    \n",
    "    boxes = list()\n",
    "    for i in range(len(yhat)):\n",
    "        boxes += decode_netout(yhat[i][0],\n",
    "                               anchors[i],\n",
    "                               class_threshold,\n",
    "                               model_input_shape[0],\n",
    "                               model_input_shape[1]\n",
    "                            )\n",
    "\n",
    "    rescale_yolo_boxes(boxes, original_width, original_height, model_input_shape[0], model_input_shape[1])\n",
    "\n",
    "    do_nms(boxes, 0.5)\n",
    "\n",
    "    v_boxes, v_labels, v_scores = filter_boxes(boxes, labels, class_threshold)\n",
    "\n",
    "    # summarize what we found\n",
    "    for i in range(len(v_boxes)):\n",
    "        box = v_boxes[i]\n",
    "        xmin, ymin, xmax, ymax = box.xmin, box.ymin, box.xmax, box.ymax\n",
    "        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0,255,0), 1)\n",
    "        print(v_labels[i], v_scores[i])\n",
    "\n",
    "    cv2.imshow('Video', frame)\n",
    "    count += 1\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time taken\n",
    "\n",
    "|After Fn call       | Frames processed/10sec|\n",
    "|--------------------|---------------|\n",
    "|yhat:               |72frames(10.9s)|\n",
    "|Decode_netout:      |17frames(10.6s)|\n",
    "|rescale_yolo_boxes: |15frames(10.5s)|\n",
    "|do_nms:             |03frames(11.9s)|\n",
    "|filter boxes:       |02frames(11.6s)|\n",
    "|final:              |02frames(11.7s)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References:\n",
    "1. https://www.youtube.com/watch?v=NYT1KFE1X2o&ab_channel=VikasJha\n",
    "2. https://github.com/experiencor/keras-yolo3\n",
    "3. https://machinelearningmastery.com/how-to-perform-object-detection-with-yolov3-in-keras/\n",
    "4. https://www.tensorflow.org/install/gpu"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8316a29ef95f2fde8aa419f9a822e32c69d80ac6a587f90fc924c730e5e72c61"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('RealTimeIntruderNotifier': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}